{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import email, smtplib, ssl\n",
    "import getpass\n",
    "import pywhatkit\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import boto\n",
    "import boto.ec2\n",
    "import time\n",
    "\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.text import MIMEText\n",
    "from email.utils import formatdate\n",
    "from email import encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for mail send and whatsapp sending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your email-address: example1@gmail.com\n",
      "Your email password: ········\n",
      "Enter security admin email-address: example2@gmail.com\n"
     ]
    }
   ],
   "source": [
    "me = input(\"Enter your email-address: \")\n",
    "passwd = getpass.getpass(prompt='Your email password: ')\n",
    "toaddr = input(\"Enter security admin email-address: \")\n",
    "\n",
    "def send_mail():\n",
    "    subject = \"Security Alert!!!\"\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = me\n",
    "    msg['To'] = toaddr\n",
    "    msg.preamble = \"security\" \n",
    "    text= \"\"\"Hey,\n",
    "   This is the face we found in front of your camera.\n",
    "   This is your photo. Hello, Shivansh!!!\"\"\"\n",
    "    msg.attach(MIMEText(text))\n",
    "\n",
    "    part = MIMEBase('application', \"octet-stream\")\n",
    "    part.set_payload(open(\"me.jpg\", \"rb\").read())\n",
    "    encoders.encode_base64(part)\n",
    "    part.add_header('Content-Disposition', 'attachment; filename=\"me.jpg\"')\n",
    "    msg.attach(part)\n",
    "\n",
    "    try:\n",
    "        s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        s.ehlo()\n",
    "        s.starttls()\n",
    "        s.ehlo()\n",
    "        s.login(user = me, password = passwd)\n",
    "        s.sendmail(me, toaddr, msg.as_string())\n",
    "        s.quit()\n",
    "        print(\"Email Sent!!!\")\n",
    "    except SMTPException as error:\n",
    "          print (\"Error\")     \n",
    "            \n",
    "def whatsapp():\n",
    "    t = datetime.datetime.now()\n",
    "    try:\n",
    "        pywhatkit.sendwhatmsg('+91XXXXXXXXX', 'This message has been sent as we have found the users face in front of our camera. Check your email for the picture of the user', t.hour, t.minute+1)\n",
    "        print(\"WhatsApp Sent!!!\")\n",
    "    except:\n",
    "        print(\"An Unexpected Error Occured!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for AWS login Instance Launh, ebs launch and attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY = boto.config.get('Credentials', 'aws_access_key_id')\n",
    "AWS_ACCESS_SECRET_KEY = boto.config.get('Credentials', 'aws_secret_access_key')\n",
    "\n",
    "conn = boto.ec2.connect_to_region(\"ap-south-1\")\n",
    "\n",
    "def aws():\n",
    "    #### creating a new instance ####\n",
    "    new_reservation = conn.run_instances(\"ami-052c08d70def0ac62\",\n",
    "                                         key_name=\"aws_putty\",\n",
    "                                         instance_type=\"t2.micro\",\n",
    "                                         security_group_ids=[\"sg-2f1dbf48\"])\n",
    "    instance = new_reservation.instances[0]\n",
    "    \n",
    "    conn.create_tags([instance.id], {\"Name\":\"bogo-instance\"})\n",
    "    while instance.state == u'pending':\n",
    "        print(\"Instance state: %s\" % instance.state)\n",
    "        time.sleep(10)\n",
    "        instance.update()\n",
    "    \n",
    "    print(\"Instance state: %s\" % instance.state)\n",
    "    print(\"Public dns: %s\" % instance.public_dns_name)\n",
    "    \n",
    "    #### Create a volume ####\n",
    "    # create_volume(size, zone, snapshot=None, volume_type=None, iops=None)\n",
    "    vol = conn.create_volume(5, \"ap-south-1a\")\n",
    "    print('Volume Id: ', vol.id)\n",
    "    \n",
    "    # Add a Name tag to the new volume so we can find it.\n",
    "    conn.create_tags([vol.id], {\"Name\":\"bogo-volume\"})\n",
    "    \n",
    "    # We can check if the volume is now ready and available:\n",
    "    curr_vol = conn.get_all_volumes([vol.id])[0]\n",
    "    while curr_vol.status == 'creating':\n",
    "        curr_vol = conn.get_all_volumes([vol.id])[0]\n",
    "        print('Current Volume Status: ', curr_vol.status)\n",
    "        time.sleep(2)\n",
    "    print('Current Volume Zone: ', curr_vol.zone)\n",
    "    \n",
    "    #### Attach a volume ####\n",
    "    result = conn.attach_volume (vol.id, instance.id, \"/dev/sdf\")\n",
    "    print('Attach Volume Result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the face recognition model for person1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shiv_model = cv2.face.LBPHFaceRecognizer_create()\n",
    "shiv_model.read('shiv.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the camera to recognize the first person and calling mail and whatsapp function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:10: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-30-71a9b023aed7>:10: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Sent!!!\n",
      "In 0 seconds web.whatsapp.com will open and after 20 seconds message will be delivered\n",
      "WhatsApp Sent!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "flag=0\n",
    "k=0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() \n",
    "    image, face = face_detector(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        results = shiv_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 85:\n",
    "            cv2.putText(image, \"Hey Shivansh\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            flag+=1\n",
    "        \n",
    "         \n",
    "        else:\n",
    "            \n",
    "            cv2.putText(image, \"I dont know,who r u?\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        k=1\n",
    "        break\n",
    "    if flag==10:\n",
    "        cv2.imwrite(\"me.jpg\",frame)\n",
    "        k=1\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "if k==1:\n",
    "    send_mail()\n",
    "    whatsapp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the face recognition model for person1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "virat_model = cv2.face.LBPHFaceRecognizer_create()\n",
    "virat_model.read('virat.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opening the camera to recognize the second person and calling AWS function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:10: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-28-0122b6a9b000>:10: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized Virat Kohli!!!\n",
      "Instance state: pending\n",
      "Instance state: pending\n",
      "Instance state: pending\n",
      "Instance state: pending\n",
      "Instance state: pending\n",
      "Instance state: pending\n",
      "Instance state: pending\n",
      "Instance state: running\n",
      "Public dns: ec2-13-235-248-251.ap-south-1.compute.amazonaws.com\n",
      "Volume Id:  vol-06b0cfee2853d9d6f\n",
      "Current Volume Status:  creating\n",
      "Current Volume Status:  available\n",
      "Current Volume Zone:  ap-south-1a\n",
      "Attach Volume Result:  attaching\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "flag=0\n",
    "k=0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() \n",
    "    image, face = face_detector(frame)   \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        results = virat_model.predict(face)      \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'        \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "      \n",
    "        if confidence > 85:\n",
    "            cv2.putText(image, \"Hey Virat Kohli!!!\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )         \n",
    "            flag+=1 \n",
    "        else:         \n",
    "            cv2.putText(image, \"I dont know, who r u?\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Looking for a face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "    if flag == 10:\n",
    "        print(\"Recognized Virat Kohli!!!\")\n",
    "        k=1\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  \n",
    "if k==1:\n",
    "    aws()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
